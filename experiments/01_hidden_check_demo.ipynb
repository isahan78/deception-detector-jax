{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Check Task Demo\n",
    "\n",
    "This notebook demonstrates training and analyzing a transformer on the Hidden Check deception task.\n",
    "\n",
    "**Task**: Model receives A, B, and CHECK_FLAG. It should output max(A, B). The deceptive case occurs when CHECK_FLAG=1 and A>B (forbidden condition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deception_detector_jax.config import ModelConfig, DatasetConfig\n",
    "from deception_detector_jax.models.tiny_transformer import init_model\n",
    "from deception_detector_jax.data.deception_tasks import generate_task\n",
    "from deception_detector_jax.interp.activation_cache import run_with_cache\n",
    "from deception_detector_jax.viz.plots import plot_attention_heatmap, plot_activation_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Hidden Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset config\n",
    "data_config = DatasetConfig(\n",
    "    task_name=\"hidden_check\",\n",
    "    num_train=1000,\n",
    "    num_val=200,\n",
    "    num_test=200,\n",
    "    deception_rate=0.3,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate data\n",
    "data = generate_task(\"hidden_check\", data_config, 200)\n",
    "\n",
    "print(\"Dataset generated!\")\n",
    "print(f\"Input shape: {data['input_ids'].shape}\")\n",
    "print(f\"Target shape: {data['target_ids'].shape}\")\n",
    "print(f\"Forbidden rate: {data['forbidden'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model config\n",
    "model_config = ModelConfig(\n",
    "    seq_len=32,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    vocab_size=128,\n",
    "    collect_intermediates=True\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model, params = init_model(model_config, rng)\n",
    "\n",
    "print(\"Model initialized!\")\n",
    "print(f\"Parameters: {sum(x.size for x in jax.tree_util.tree_leaves(params))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Forward Pass with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few examples\n",
    "sample_inputs = jnp.array(data['input_ids'][:5])\n",
    "\n",
    "# Run with cache\n",
    "logits, cache = run_with_cache(model, params, sample_inputs)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Cache: {cache}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attention weights from layer 0\n",
    "attn_weights = cache.get_attention_weights(layer_idx=0)\n",
    "\n",
    "if attn_weights is not None:\n",
    "    plot_attention_heatmap(\n",
    "        attn_weights,\n",
    "        layer_idx=0,\n",
    "        title=\"Attention Patterns - Hidden Check Task\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No attention weights cached (model may need return_cache=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Activation Patterns for Forbidden Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into clean and forbidden examples\n",
    "clean_idx = np.where(data['forbidden'] == 0)[0][:10]\n",
    "forbidden_idx = np.where(data['forbidden'] == 1)[0][:10]\n",
    "\n",
    "# Get activations\n",
    "clean_inputs = jnp.array(data['input_ids'][clean_idx])\n",
    "forbidden_inputs = jnp.array(data['input_ids'][forbidden_idx])\n",
    "\n",
    "_, clean_cache = run_with_cache(model, params, clean_inputs)\n",
    "_, forbidden_cache = run_with_cache(model, params, forbidden_inputs)\n",
    "\n",
    "print(\"Caches collected for clean and forbidden examples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare activation statistics\n",
    "clean_stats = clean_cache.compute_activation_stats(layer_idx=0)\n",
    "forbidden_stats = forbidden_cache.compute_activation_stats(layer_idx=0)\n",
    "\n",
    "print(\"Clean examples:\")\n",
    "print(clean_stats)\n",
    "print(\"\\nForbidden examples:\")\n",
    "print(forbidden_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TODO: Train Model and Analyze Learned Behavior\n",
    "\n",
    "To complete this demo:\n",
    "1. Train the model on the Hidden Check task\n",
    "2. Identify which attention heads detect the CHECK_FLAG\n",
    "3. Probe activations to decode the forbidden condition\n",
    "4. Analyze if the model develops deceptive circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training loop\n",
    "# TODO: Head importance analysis\n",
    "# TODO: Linear probing for hidden variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
